{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a344f614",
      "metadata": {},
      "source": [
        "# Huggett (1993) Model with Aggregate Risk\n",
        "\n",
        "Heterogeneous-agent economy: individuals have uninsured idiosyncratic labor income risk and save in bonds; bonds are in **zero net supply**. Aggregate TFP $z_t$ is stochastic. The interest rate $r_t$ clears the bond market.\n",
        "\n",
        "**Individual state:** $(b, y)$ — bond holdings and idiosyncratic income.  \n",
        "**Aggregate state:** $z$ (and in equilibrium, the cross-sectional distribution).  \n",
        "**Budget:** $c + b' = (1+r)b + y\\,z$, with borrowing constraint $b \\geq \\underline{b}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed37fc0d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "np.random.seed(42)\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45e1e82d",
      "metadata": {},
      "source": [
        "## Global parameters (SRL Appendix A.1 — Table 2 & Section 4.1)\n",
        "\n",
        "- **Preferences:** $E_0 \\sum_{t=0}^\\infty \\beta^t u(c_t)$, isoelastic $u(c) = \\frac{c^{1-\\sigma}}{1-\\sigma}$.\n",
        "- **Idiosyncratic income** $y_t$: log AR(1), persistence $\\rho_y$, innovation volatility $\\nu_y$; discretized (e.g. Tauchen) on $n_y$ points.\n",
        "- **Aggregate income** $z_t$: log AR(1), persistence $\\rho_z$, volatility $\\nu_z$; discretized (Tauchen) on $n_z$ points.\n",
        "- **Bonds:** borrowing limit $\\underline{b}$, total bond supply $B = 0$ (zero net supply).\n",
        "- **PE only:** exogenous interest rate process $r_t$ (mean $\\bar{r}$, persistence $\\rho_r$, volatility $\\nu_r$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0303667",
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Calibration (Table 2: Huggett model calibration) ===\n",
        "# We interpret one period as a year (Section 4.1).\n",
        "\n",
        "# Preferences\n",
        "beta = 0.96       # discount factor\n",
        "sigma = 2.0       # coefficient of relative risk aversion (CRRA)\n",
        "\n",
        "# Idiosyncratic labor income: log AR(1) with persistence ρy, innovation volatility νy\n",
        "rho_y = 0.6\n",
        "nu_y = 0.2\n",
        "\n",
        "# Aggregate TFP z: log AR(1)\n",
        "rho_z = 0.9\n",
        "nu_z = 0.02\n",
        "\n",
        "# Bonds\n",
        "B = 0.0          # total bond supply (zero net supply)\n",
        "b_min = -1.0     # borrowing constraint (b ≥ b_min)\n",
        "\n",
        "# Partial equilibrium only: exogenous interest rate process r_t\n",
        "# r_{t+1} = (1-ρr)*r_bar + ρr*r_t + νr*sqrt(max(r_t,0))*ε,  ε ~ N(0,1)\n",
        "r_bar = 0.038    # long-run mean interest rate (PE)\n",
        "rho_r = 0.8      # autocorrelation of r (PE)\n",
        "nu_r = 0.02      # volatility of r (PE)\n",
        "\n",
        "# === Discretization (Table 3: hyperparameters) ===\n",
        "nb = 200         # number of bond grid points\n",
        "b_max = 50.0     # upper bound of bond grid\n",
        "ny = 3           # number of y grid points (idiosyncratic income)\n",
        "nr = 20          # number of r grid points (for PE or GE approximation)\n",
        "r_min = 0.01     # lower bound of r grid [r_L, r_H]\n",
        "r_max = 0.06     # upper bound of r grid\n",
        "nz = 30          # number of z grid points (aggregate TFP)\n",
        "\n",
        "# Truncation and numerics (Appendix A.1)\n",
        "c_min = 1e-3     # minimum consumption floor (avoids u(c) at 0)\n",
        "etrunc = 1e-3    # truncation tolerance: β^T < etrunc\n",
        "T_trunc = int(np.ceil(np.log(etrunc) / np.log(beta)))  # ≈ 170 for beta=0.96\n",
        "\n",
        "print(\"Huggett calibration (SRL Appendix A.1):\")\n",
        "print(f\"  β={beta}, σ={sigma}, ρy={rho_y}, νy={nu_y}, ρz={rho_z}, νz={nu_z}\")\n",
        "print(f\"  B={B}, b_min={b_min};  PE: r_bar={r_bar}, ρr={rho_r}, νr={nu_r}\")\n",
        "print(f\"  Grids: nb={nb}, b_max={b_max}, ny={ny}, nr={nr}, r∈[{r_min},{r_max}], nz={nz}\")\n",
        "print(f\"  T_trunc={T_trunc}, c_min={c_min}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc7ad1c",
      "metadata": {},
      "source": [
        "## Grids and utility\n",
        "\n",
        "- **Bond grid:** equispaced or log-spaced on $[\\underline{b},\\, b_{\\max}]$.\n",
        "- **Income grids:** Tauchen discretization of the log AR(1) processes for $y$ and $z$ (to be implemented)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d93b70f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bond grid: nb points on [b_min, b_max] (Appendix: nb=200, bmax=50)\n",
        "b_grid = np.linspace(b_min, b_max, nb)\n",
        "\n",
        "# CRRA utility and derivative (for FOC / Euler)\n",
        "def u(c, sig=sigma):\n",
        "    \"\"\"u(c) = c^(1-σ)/(1-σ); limit for σ=1 is log(c).\"\"\"\n",
        "    c = np.maximum(c, c_min)\n",
        "    if np.abs(sig - 1.0) < 1e-10:\n",
        "        return np.log(c)\n",
        "    return (c ** (1 - sig)) / (1 - sig)\n",
        "\n",
        "def u_prime(c, sig=sigma):\n",
        "    \"\"\"u'(c) = c^(-σ).\"\"\"\n",
        "    c = np.maximum(c, c_min)\n",
        "    return c ** (-sig)\n",
        "\n",
        "# Placeholder: y and z grids will be built via Tauchen (same as in SRL)\n",
        "# y_grid: ny points; z_grid: nz points; transition matrices Ty, Tz\n",
        "print(\"b_grid:\", b_grid[0], \"...\", b_grid[-1], \"shape\", b_grid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1542106",
      "metadata": {},
      "outputs": [],
      "source": [
        "# return the grid and the transition matrix\n",
        "def tauchen_ar1(rho, sigma_innov, n_states, m=3):\n",
        "    \"\"\"\n",
        "    Tauchen (1986): discretize AR(1) x' = rho*x + eps, eps ~ N(0, sigma_innov^2).\n",
        "    Returns grid (n_states,) and transition matrix (n_states, n_states).\n",
        "    m: number of std devs for the state grid (wider grid for persistence).\n",
        "    \"\"\"\n",
        "    sigma_x = sigma_innov / np.sqrt(1 - rho**2)\n",
        "    x_min = -m * sigma_x\n",
        "    x_max = m * sigma_x\n",
        "    x_grid = np.linspace(x_min, x_max, n_states)\n",
        "    step = (x_max - x_min) / (n_states - 1)\n",
        "    P = np.zeros((n_states, n_states))\n",
        "    # the way to discretize is by integrating over the interval length of step and centraled by the value of x_grid\n",
        "    for i in range(n_states):\n",
        "        for j in range(n_states):\n",
        "            if j == 0:\n",
        "                P[i, j] = norm.cdf((x_grid[j] - rho * x_grid[i] + step / 2) / sigma_innov)\n",
        "            elif j == n_states - 1:\n",
        "                P[i, j] = 1 - norm.cdf((x_grid[j] - rho * x_grid[i] - step / 2) / sigma_innov)\n",
        "            else:\n",
        "                P[i, j] = (norm.cdf((x_grid[j] - rho * x_grid[i] + step / 2) / sigma_innov) -\n",
        "                           norm.cdf((x_grid[j] - rho * x_grid[i] - step / 2) / sigma_innov))\n",
        "    P = P / P.sum(axis=1, keepdims=True)\n",
        "    return x_grid, P\n",
        "\n",
        "# Idiosyncratic income y: log y follows AR(1) with rho_y, nu_y. Grid in logs then exp.\n",
        "log_y_grid, Ty = tauchen_ar1(rho_y, nu_y, ny)\n",
        "y_grid = np.exp(log_y_grid)\n",
        "# Normalize so E[y]=1 in stationary distribution (optional)\n",
        "invariant_y = np.linalg.matrix_power(Ty.T, 200)[:, 0]\n",
        "y_grid = y_grid / (y_grid @ invariant_y)\n",
        "\n",
        "# Aggregate z: log z follows AR(1) with rho_z, nu_z\n",
        "log_z_grid, Tz = tauchen_ar1(rho_z, nu_z, nz)\n",
        "z_grid = np.exp(log_z_grid)\n",
        "invariant_z = np.linalg.matrix_power(Tz.T, 200)[:, 0]\n",
        "z_grid = z_grid / (z_grid @ invariant_z)\n",
        "\n",
        "# Idiosyncratic income y: log y follows AR(1) with rho=0.9, volatility=0.02, 3 states\n",
        "ny = 3\n",
        "rho_y = 0.9\n",
        "nu_y = 0.02\n",
        "\n",
        "log_y_grid, Ty = tauchen_ar1(rho_y, nu_y, ny)\n",
        "y_grid = np.exp(log_y_grid)\n",
        "\n",
        "# Normalize so E[y]=1 in stationary distribution (optional)\n",
        "invariant_y = np.linalg.matrix_power(Ty.T, 200)[:, 0]\n",
        "y_grid = y_grid / (y_grid @ invariant_y)\n",
        "\n",
        "print(\"y_grid (idiosyncratic, AR(1), 3 values):\", y_grid)\n",
        "print(\"Ty (idiosyncratic transition matrix):\\n\", Ty)\n",
        "\n",
        "print(\"y_grid (idiosyncratic):\", y_grid)\n",
        "print(\"z_grid (aggregate, first 5 ... last 2):\", z_grid[:5], \"...\", z_grid[-2:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156e95f2",
      "metadata": {},
      "source": [
        "## Simulation (Figure 2: computational graph)\n",
        "\n",
        "Per period: **state** $(g_t, z_t)$ → **price** $p_t = r_t$ (from $P^*$ or market clearing) → **policy** $\\pi(s_t, p_t, z_t)$ → **consumption** $c_t$ → **aggregation** $A_\\pi(p_t, z_t)$ → next state $(g_{t+1}, z_{t+1})$. We simulate $N$ agents for $T$ periods and optionally compute $\\hat{v}_\\pi$ (e.g. discounted utility)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef86403",
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.interpolate import interp2d, LinearNDInterpolator\n",
        "from scipy.optimize import brentq\n",
        "\n",
        "def policy_placeholder(b, y, r, z, save_frac=0.2):\n",
        "    \"\"\"\n",
        "    Placeholder policy π(b, y, r, z): returns (c, b_next).\n",
        "    Cash on hand = (1+r)*b + y*z; save save_frac, consume the rest; b' clamped to [b_min, b_max].\n",
        "    Replace with VFI/SRL policy later.\n",
        "    \"\"\"\n",
        "    cash = (1 + r) * b + y * z\n",
        "    b_next = np.clip(save_frac * cash, b_min, b_max)\n",
        "    c = np.maximum(cash - b_next, c_min)\n",
        "    return c, b_next\n",
        "\n",
        "def draw_next_state(y_idx, z_idx, Ty, Tz):\n",
        "    \"\"\"Draw (y_{t+1} index, z_{t+1} index) from Ty[y_idx,:] and Tz[z_idx,:].\"\"\"\n",
        "    y_next = np.searchsorted(np.cumsum(Ty[y_idx, :]), np.random.rand())\n",
        "    z_next = np.searchsorted(np.cumsum(Tz[z_idx, :]), np.random.rand())\n",
        "    return y_next, z_next\n",
        "\n",
        "def pe_r_next(r_t):\n",
        "    \"\"\"PE: next interest rate r_{t+1} = (1-ρr)*r_bar + ρr*r_t + νr*sqrt(max(r_t,0))*ε.\"\"\"\n",
        "    eps = np.random.randn()\n",
        "    r_next = (1 - rho_r) * r_bar + rho_r * r_t + nu_r * np.sqrt(max(r_t, 1e-8)) * eps\n",
        "    return np.clip(r_next, r_min, r_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05faaceb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def aggregate_saving(b_vec, y_vec, r, z, policy_fn):\n",
        "    \"\"\"Total (average) saving b' given current (b_vec, y_vec), price r, aggregate z, and policy π.\"\"\"\n",
        "    c, b_next = policy_fn(b_vec, y_vec, r, z)\n",
        "    return np.mean(b_next)\n",
        "\n",
        "def ge_price(b_vec, y_vec, z, policy_fn, r_lo=None, r_hi=None):\n",
        "    \"\"\"\n",
        "    P*(g_t, z_t): find r_t such that aggregate saving = B (market clearing).\n",
        "    In Huggett, B=0 so we solve mean(b') = 0.\n",
        "    \"\"\"\n",
        "    r_lo = r_min if r_lo is None else r_lo\n",
        "    r_hi = r_max if r_hi is None else r_hi\n",
        "    def excess_saving(r):\n",
        "        return aggregate_saving(b_vec, y_vec, r, z, policy_fn) - B\n",
        "    if excess_saving(r_lo) * excess_saving(r_hi) > 0:\n",
        "        return np.clip(r_bar, r_lo, r_hi)  # fallback if no crossing\n",
        "    return brentq(excess_saving, r_lo, r_hi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dcc075a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def simulate_huggett(\n",
        "    T,\n",
        "    N_agents,\n",
        "    policy_fn,\n",
        "    y_grid, z_grid, Ty, Tz,\n",
        "    general_eq=True,\n",
        "    r0=None,\n",
        "    z0_idx=None,\n",
        "    b0=None,\n",
        "    y0_idx=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Simulate the Huggett economy for T periods, N_agents (Figure 2).\n",
        "\n",
        "    Returns:\n",
        "        paths: dict with 'b', 'y_idx', 'y', 'z_idx', 'z', 'r', 'c', shape (T+1,) or (T+1, N_agents)\n",
        "        v_hat: scalar, sum_t β^t * mean(u(c_t)) (optional aggregate value v̂_π)\n",
        "    \"\"\"\n",
        "    # Initialize: draw initial y, z from stationary distribution; b from grid or zeros\n",
        "    if z0_idx is None:\n",
        "        z0_idx = np.random.randint(0, len(z_grid))\n",
        "    if y0_idx is None:\n",
        "        y0_idx = np.random.randint(0, len(y_grid), size=N_agents)\n",
        "    if b0 is None:\n",
        "        b0 = np.zeros(N_agents)  # start at b=0; or draw from some distribution\n",
        "    if r0 is None:\n",
        "        r0 = r_bar if not general_eq else None\n",
        "\n",
        "    b = b0.copy()\n",
        "    y_idx = y0_idx.copy()\n",
        "    z_idx = np.array([z0_idx])\n",
        "\n",
        "    paths = {\n",
        "        'b': np.zeros((T + 1, N_agents)),\n",
        "        'y_idx': np.zeros((T + 1, N_agents), dtype=int),\n",
        "        'y': np.zeros((T + 1, N_agents)),\n",
        "        'z_idx': np.zeros(T + 1, dtype=int),\n",
        "        'z': np.zeros(T + 1),\n",
        "        'r': np.zeros(T + 1),\n",
        "        'c': np.zeros((T + 1, N_agents)),\n",
        "    }\n",
        "    paths['b'][0] = b\n",
        "    paths['y_idx'][0] = y_idx\n",
        "    paths['y'][0] = y_grid[y_idx]\n",
        "    paths['z_idx'][0] = z_idx[0]\n",
        "    paths['z'][0] = z_grid[z_idx[0]]\n",
        "    paths['r'][0] = r0 if r0 is not None else np.nan\n",
        "    paths['c'][0] = np.nan  # no c at t=0 before decision\n",
        "\n",
        "    for t in range(T):\n",
        "        z_val = z_grid[z_idx[0]]\n",
        "        y_val = y_grid[y_idx]\n",
        "\n",
        "        # Price p_t = r_t: GE = market clearing, PE = exogenous\n",
        "        if general_eq:\n",
        "            r_t = ge_price(b, y_val, z_val, policy_fn)\n",
        "        else:\n",
        "            r_t = paths['r'][t]  # use current r (set at t=0 or from previous step)\n",
        "\n",
        "        paths['r'][t] = r_t\n",
        "\n",
        "        # Policy π(s_t, p_t, z_t) → c_t, b'_t\n",
        "        c_t, b_next = policy_fn(b, y_val, r_t, z_val)\n",
        "        paths['c'][t] = c_t\n",
        "\n",
        "        # A_π: next state — update b'; draw y', z'\n",
        "        b = b_next\n",
        "        paths['b'][t + 1] = b\n",
        "        y_idx_next = np.array([draw_next_state(y_idx[i], z_idx[0], Ty, Tz)[0] for i in range(N_agents)])\n",
        "        z_idx_next = np.searchsorted(np.cumsum(Tz[z_idx[0], :]), np.random.rand())\n",
        "        y_idx = y_idx_next\n",
        "        z_idx[0] = z_idx_next\n",
        "\n",
        "        paths['y_idx'][t + 1] = y_idx\n",
        "        paths['y'][t + 1] = y_grid[y_idx]\n",
        "        paths['z_idx'][t + 1] = z_idx[0]\n",
        "        paths['z'][t + 1] = z_grid[z_idx[0]]\n",
        "        if not general_eq:\n",
        "            paths['r'][t + 1] = pe_r_next(r_t)\n",
        "    if general_eq:\n",
        "        paths['r'][T] = paths['r'][T - 1]\n",
        "    paths['c'][T] = policy_placeholder(paths['b'][T], paths['y'][T], paths['r'][T], paths['z'][T])[0]\n",
        "\n",
        "    # v̂_π: discounted average utility (over agents and time)\n",
        "    c_path = paths['c'][:T]\n",
        "    v_hat = np.sum([(beta ** t) * np.mean(u(c_path[t])) for t in range(T)])\n",
        "\n",
        "    return paths, v_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43274d3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wrapper: policy must take (b, y, r, z) and return (c, b_next)\n",
        "def policy_fn(b, y, r, z):\n",
        "    return policy_placeholder(b, y, r, z, save_frac=0.2)\n",
        "\n",
        "T_sim = 100\n",
        "N_agents = 2000\n",
        "\n",
        "# General equilibrium: r_t clears bond market each period\n",
        "paths_ge, v_ge = simulate_huggett(\n",
        "    T_sim, N_agents, policy_fn, y_grid, z_grid, Ty, Tz,\n",
        "    general_eq=True, r0=None, b0=np.zeros(N_agents),\n",
        ")\n",
        "print(\"GE simulation done. v̂_π (discounted avg utility):\", v_ge)\n",
        "print(\"Mean r (GE):\", np.nanmean(paths_ge['r']))\n",
        "print(\"Mean aggregate b (should ≈ 0):\", np.mean(paths_ge['b'], axis=1)[:5], \"...\")\n",
        "\n",
        "# Optional: PE simulation with exogenous r process\n",
        "paths_pe, v_pe = simulate_huggett(\n",
        "    T_sim, N_agents, policy_fn, y_grid, z_grid, Ty, Tz,\n",
        "    general_eq=False, r0=r_bar, b0=np.zeros(N_agents),\n",
        ")\n",
        "print(\"PE simulation done. v̂_π:\", v_pe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dd29c23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot simulated paths (Figure 2 outputs: z_t, r_t, c_t)\n",
        "fig, axes = plt.subplots(3, 1, figsize=(10, 8), sharex=True)\n",
        "t_axis = np.arange(T_sim + 1)\n",
        "axes[0].plot(t_axis, paths_ge['z'], 'b-', label='z (TFP)')\n",
        "axes[0].set_ylabel('z')\n",
        "axes[0].legend(loc='upper right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[1].plot(t_axis, paths_ge['r'], 'g-', label='r (interest rate)')\n",
        "axes[1].set_ylabel('r')\n",
        "axes[1].legend(loc='upper right')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "mean_c = np.mean(paths_ge['c'], axis=1)\n",
        "axes[2].plot(t_axis, mean_c, 'r-', label='mean(c)')\n",
        "axes[2].set_ylabel('mean(c)')\n",
        "axes[2].set_xlabel('t')\n",
        "axes[2].legend(loc='upper right')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "plt.suptitle('Huggett simulation (GE): state z_t, price r_t, consumption c_t')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec0d3160",
      "metadata": {},
      "source": [
        "## SRL / SPG: Gradient-stop on macro, gradient descent on policy (SRL Section 3.2–3.3)\n",
        "\n",
        "**Objective:** Maximize expected lifetime utility\n",
        "\n",
        "$$L(\\theta) = d_0^T \\hat{v}_\\pi$$\n",
        "\n",
        "where $\\hat{v}_\\pi$ is the sample average over $N$ simulated trajectories (Monte Carlo).\n",
        "\n",
        "**Macro (no gradient):** The price $p_t = P^*(g_t, z_t)$ is given by market clearing. We apply **stop-gradient** to $p_t$, so $\\partial p_t / \\partial \\theta = 0$ — agents take prices as given.\n",
        "\n",
        "**Micro (differentiate):** The policy $\\pi(\\cdot; \\theta)$ and the transition matrix $A_\\pi(z, p)$ depend on $\\theta$; we backpropagate through them and through $u(c)$.\n",
        "\n",
        "**Update:** Stochastic gradient ascent\n",
        "\n",
        "$$\\theta_{k+1} = \\theta_k + \\eta_k \\nabla_\\theta L(\\theta_k)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90512fb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# SRL/SPG: PyTorch for autograd; gradient-stop on prices\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dtype = torch.float32\n",
        "\n",
        "# Coarser grid for SPG (Appendix Table 3: nb=200, but we use smaller for speed)\n",
        "nb_spg = 50\n",
        "nr_spg = 10\n",
        "nz_spg = 10\n",
        "# ny, b_min, b_max, etc. from above; use same y_grid, z_grid, Ty, Tz (or subsample)\n",
        "J = nb_spg * ny  # individual states: (b_idx, y_idx) -> j = b_idx*ny + y_idx\n",
        "\n",
        "# Build SPG grids (can subsample from main grids)\n",
        "b_grid_spg = torch.tensor(np.linspace(b_min, b_max, nb_spg), dtype=dtype, device=device)\n",
        "# Subsample z and r for SPG\n",
        "iz_spg = np.linspace(0, nz-1, nz_spg, dtype=int)\n",
        "ir_spg = np.linspace(0, nr-1, nr_spg, dtype=int) if nr <= 20 else np.arange(nr_spg)\n",
        "z_grid_t = torch.tensor(z_grid[iz_spg], dtype=dtype, device=device)\n",
        "r_grid_t = torch.tensor(np.linspace(r_min, r_max, nr_spg), dtype=dtype, device=device)\n",
        "y_grid_t = torch.tensor(y_grid, dtype=dtype, device=device)\n",
        "Ty_t = torch.tensor(Ty, dtype=dtype, device=device)\n",
        "Tz_sub = Tz[np.ix_(iz_spg, iz_spg)] if len(iz_spg) <= nz else Tz\n",
        "Tz_sub = Tz_sub / Tz_sub.sum(axis=1, keepdims=True)\n",
        "Tz_t = torch.tensor(Tz_sub, dtype=dtype, device=device)\n",
        "nz_spg = Tz_t.shape[0]\n",
        "\n",
        "# Policy parameter θ: consumption c on (J, nz_spg, nr_spg) grid. Initialize near steady-state consumption.\n",
        "# c(s,z,p) = θ[j, iz, ir]. Budget: b' = (1+r)*b + y*z - c, clamped.\n",
        "def theta_to_consumption_grid(theta, b_grid_t, y_grid_t, z_grid_t, r_grid_t, c_min_val=1e-3):\n",
        "    \"\"\"θ shape (J, nz, nr) -> c same shape, ensured >= c_min.\"\"\"\n",
        "    return torch.nn.functional.softplus(theta) + c_min_val\n",
        "\n",
        "# Initial θ: imply consumption from a constant saving rule (e.g. c = (1-ss)*cash)\n",
        "def init_theta(b_grid_t, y_grid_t, z_grid_t, r_grid_t, save_frac=0.2):\n",
        "    J, nz, nr = len(b_grid_t)*len(y_grid_t), len(z_grid_t), len(r_grid_t)\n",
        "    c_grid = torch.zeros(J, nz, nr, dtype=dtype, device=device)\n",
        "    for ib in range(len(b_grid_t)):\n",
        "        for iy in range(len(y_grid_t)):\n",
        "            j = ib * len(y_grid_t) + iy\n",
        "            b = b_grid_t[ib].item()\n",
        "            y = y_grid_t[iy].item()\n",
        "            for iz in range(nz):\n",
        "                z = z_grid_t[iz].item()\n",
        "                for ir in range(nr):\n",
        "                    r = r_grid_t[ir].item()\n",
        "                    cash = (1 + r) * b + y * z\n",
        "                    c = max((1 - save_frac) * cash, c_min)\n",
        "                    c_grid[j, iz, ir] = c\n",
        "    # inverse of softplus: theta such that softplus(theta)+c_min = c_grid\n",
        "    x = c_grid - c_min\n",
        "    theta_init = torch.log(torch.exp(x) - 1 + 1e-8)\n",
        "    return theta_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2729ccf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build transition matrix A_π(z, p) from θ. A_π is J×J; differentiable in θ. Use detached p for macro.\n",
        "def build_A_pi(theta, iz, ir, b_grid_t, y_grid_t, z_grid_t, r_grid_t, Ty_t, nb_spg, ny, sigma_b=0.1):\n",
        "    \"\"\"\n",
        "    A_π[j', j] = P(s'=j' | s=j) under policy θ at (z_grid[iz], r_grid[ir]).\n",
        "    b' = (1+r)*b + y*z - c; map b' to b-grid via soft weights for differentiability.\n",
        "    \"\"\"\n",
        "    J = nb_spg * ny\n",
        "    z_val = z_grid_t[iz]\n",
        "    r_val = r_grid_t[ir]\n",
        "    c = theta_to_consumption_grid(theta, b_grid_t, y_grid_t, z_grid_t, r_grid_t)\n",
        "    c_val = c[:, iz, ir]  # (J,)\n",
        "    b_next = (1 + r_val) * b_grid_t.repeat_interleave(ny) + y_grid_t.repeat(nb_spg) * z_val - c_val\n",
        "    b_next = torch.clamp(b_next, b_min, b_max)\n",
        "    # Soft weights: weight_ib = exp(-(b'-b_grid[ib])^2/(2*sigma^2)), normalized\n",
        "    dist = b_next.unsqueeze(1) - b_grid_t.unsqueeze(0)  # (J, nb)\n",
        "    w_b = torch.exp(-dist.pow(2) / (2 * sigma_b**2))\n",
        "    w_b = w_b / (w_b.sum(dim=1, keepdim=True) + 1e-8)\n",
        "    # A_π: from j=(ib,iy) to j'=(ib',iy'): weight_b(ib') * Ty[iy, iy']\n",
        "    A = torch.zeros(J, J, dtype=dtype, device=device)\n",
        "    for j in range(J):\n",
        "        ib, iy = j // ny, j % ny\n",
        "        for ibp in range(nb_spg):\n",
        "            for iyp in range(ny):\n",
        "                jp = ibp * ny + iyp\n",
        "                A[jp, j] = w_b[j, ibp] * Ty_t[iy, iyp]\n",
        "    return A\n",
        "\n",
        "def aggregate_saving_grid(theta, d, iz, ir, b_grid_t, y_grid_t, z_grid_t, r_grid_t, ny):\n",
        "    \"\"\"Aggregate saving d^T b'(θ,z,r); used for market clearing.\"\"\"\n",
        "    J = d.shape[0]\n",
        "    z_val = z_grid_t[iz]\n",
        "    r_val = r_grid_t[ir]\n",
        "    c = theta_to_consumption_grid(theta, b_grid_t, y_grid_t, z_grid_t, r_grid_t)[:, iz, ir]\n",
        "    b_next = (1 + r_val) * b_grid_t.repeat_interleave(ny) + y_grid_t.repeat(nb_spg) * z_val - c\n",
        "    b_next = torch.clamp(b_next, b_min, b_max)\n",
        "    return (d * b_next).sum()\n",
        "\n",
        "def P_star_detach(theta, d, iz, b_grid_t, y_grid_t, z_grid_t, r_grid_t, ny, B=0.0):\n",
        "    \"\"\"Find ir that minimizes |aggregate_saving - B|; return r_grid_t[ir].detach() (gradient-stop).\"\"\"\n",
        "    best_ir, best_err = 0, float('inf')\n",
        "    for ir in range(len(r_grid_t)):\n",
        "        S = aggregate_saving_grid(theta, d, iz, ir, b_grid_t, y_grid_t, z_grid_t, r_grid_t, ny)\n",
        "        err = (S - B).abs().item()\n",
        "        if err < best_err:\n",
        "            best_err, best_ir = err, ir\n",
        "    return r_grid_t[best_ir].detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34969366",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39fb92c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map scalar r (e.g. detached) to grid index for policy lookup\n",
        "def r_to_ir(r_val, r_grid_t):\n",
        "    r_np = r_grid_t.detach().cpu().numpy()\n",
        "    return int(np.clip(np.searchsorted(r_np, r_val.item() if torch.is_tensor(r_val) else r_val), 0, len(r_np)-1))\n",
        "\n",
        "# Utility on grid (vector over J)\n",
        "def u_torch(c_vec, sig=sigma):\n",
        "    c_vec = torch.clamp(c_vec, min=c_min)\n",
        "    if abs(sig - 1.0) < 1e-8:\n",
        "        return torch.log(c_vec)\n",
        "    return (c_vec ** (1 - sig)) / (1 - sig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18548579",
      "metadata": {},
      "outputs": [],
      "source": [
        "# SPG: Simulate N paths with gradient-stop on p_t; maximize L(θ) = (1/N) Σ_n Σ_t β^t d_t^T u(c_t)\n",
        "def spg_objective(theta, N_traj, T_horizon, b_grid_t, y_grid_t, z_grid_t, r_grid_t, Ty_t, Tz_t,\n",
        "                  nb_spg, ny, nz_spg, nr_spg, beta_t, d0=None):\n",
        "    \"\"\"\n",
        "    L(θ) = (1/N) Σ_n Σ_t β^t (d_π,t)^T u(c_t).\n",
        "    p_t = P*(d_t, z_t) is computed and then .detach() so ∇_θ does not flow through macro.\n",
        "    \"\"\"\n",
        "    J = nb_spg * ny\n",
        "    if d0 is None:\n",
        "        d0 = torch.ones(J, device=device, dtype=dtype) / J\n",
        "    L_list = []\n",
        "    for n in range(N_traj):\n",
        "        iz = np.random.randint(0, nz_spg)\n",
        "        d = d0.clone()\n",
        "        L_n = torch.tensor(0.0, device=device, dtype=dtype)\n",
        "        for t in range(T_horizon):\n",
        "            # Price with gradient-stop (SRL: agents take prices as given)\n",
        "            r_t = P_star_detach(theta, d, iz, b_grid_t, y_grid_t, z_grid_t, r_grid_t, ny)\n",
        "            ir = r_to_ir(r_t, r_grid_t)\n",
        "            c = theta_to_consumption_grid(theta, b_grid_t, y_grid_t, z_grid_t, r_grid_t)\n",
        "            c_t = c[:, iz, ir]\n",
        "            L_n = L_n + (beta_t ** t) * (d @ u_torch(c_t))\n",
        "            A = build_A_pi(theta, iz, ir, b_grid_t, y_grid_t, z_grid_t, r_grid_t, Ty_t, nb_spg, ny)\n",
        "            d = A.T @ d\n",
        "            cum = np.cumsum(Tz_t[iz, :].detach().cpu().numpy())\n",
        "            iz = min(np.searchsorted(cum, np.random.rand()), nz_spg - 1)\n",
        "        L_list.append(L_n)\n",
        "    return torch.stack(L_list).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8c3c450",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize θ and run SPG (gradient ascent on L(θ))\n",
        "nr_spg = len(r_grid_t)\n",
        "nz_spg = len(z_grid_t)\n",
        "theta = init_theta(b_grid_spg, y_grid_t, z_grid_t, r_grid_t)\n",
        "theta = theta.requires_grad_(True)\n",
        "optimizer = torch.optim.Adam([theta], lr=1e-3)\n",
        "N_traj = 32\n",
        "T_horizon = 30\n",
        "n_epochs = 100\n",
        "loss_hist = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    optimizer.zero_grad()\n",
        "    L = spg_objective(theta, N_traj, T_horizon, b_grid_spg, y_grid_t, z_grid_t, r_grid_t, Ty_t, Tz_t,\n",
        "                      nb_spg, ny, nz_spg, nr_spg, beta)\n",
        "    loss_hist.append(L.item())\n",
        "    (-L).backward()\n",
        "    optimizer.step()\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}, L(θ) = {L.item():.6f}\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
